filter(date <= cutoff, !is.na(.data[[target_col]]), !is.na(.data[[lag1_col]])) %>%
nrow()
idx_cut <- which(df$date == cutoff)
i_start <- idx_cut + h
n <- nrow(df)
yhat_ar1      <- rep(NA_real_, n)
yhat_rw0      <- rep(0, n)
yhat_rw_drift <- rep(NA_real_, n)
yhat_hybrid   <- rep(NA_real_, n)
for (i in seq_len(n)) {
tr_end   <- i - h
tr_start <- tr_end - W + 1
if (tr_start < 1) next
# --- baselines (unchanged)
fit_ar1 <- lm(reformulate(lag1_col, response = target_col),
data = df[tr_start:tr_end, ])
yhat_ar1[i] <- predict(fit_ar1, newdata = df[i, , drop = FALSE])
mu_h <- mean(df[tr_start:tr_end, target_col, drop = TRUE], na.rm = TRUE)
yhat_rw_drift[i] <- mu_h
# --- HYBRID features: ALL except date + target (no lag filtering)
X_cols <- setdiff(names(df), c("date", target_col))
df_tr  <- df[tr_start:tr_end, c(target_col, X_cols), drop = FALSE]
df_te  <- df[i, c(target_col, X_cols), drop = FALSE]
good_tr <- complete.cases(df_tr)
if (!any(good_tr)) next
df_tr <- df_tr[good_tr, , drop = FALSE]
if (!all(complete.cases(df_te))) next
y_tr     <- df_tr[[target_col]]
X_tr_raw <- df_tr[, X_cols, drop = FALSE]
X_te_raw <- df_te[,  X_cols, drop = FALSE]
# numeric-only for Post-LASSO; RF may use factors too
num_cols <- names(X_tr_raw)[sapply(X_tr_raw, is.numeric)]
if (length(num_cols) == 0) next
X_tr_num <- as.matrix(X_tr_raw[, num_cols, drop = FALSE])
X_te_num <- as.matrix(X_te_raw[, num_cols, drop = FALSE])
std      <- standardize_train_test(X_tr_num, X_te_num)
X_tr_s   <- std$X_tr_s; X_te_s <- std$X_te_s
# your safe Post-LASSO wrapper
pl <- fit_predict_post_lasso_bic_safe(X_tr_s, y_tr, X_te_s, alpha = 1)
# RF on residuals (regularized) + OOB shrink
for (nm in names(X_tr_raw)) if (is.character(X_tr_raw[[nm]])) X_tr_raw[[nm]] <- as.factor(X_tr_raw[[nm]])
for (nm in names(X_te_raw)) if (is.character(X_te_raw[[nm]])) X_te_raw[[nm]] <- as.factor(X_te_raw[[nm]])
resid_tr <- y_tr - pl$pred_tr
p <- ncol(X_tr_raw)
nodesize <- max(5L, floor(0.05 * nrow(X_tr_raw)))
mtry     <- max(1L, floor(sqrt(p)))
rf_model <- randomForest(x = X_tr_raw, y = resid_tr,
ntree = 500, mtry = mtry, nodesize = nodesize,
importance = FALSE, keep.forest = TRUE)
rf_oob <- rf_model$predicted
denom <- sum(rf_oob^2)
w_hat <- if (is.finite(denom) && denom > 0) sum(rf_oob * resid_tr) / denom else 0
w_hat <- max(0, min(1, w_hat))
oob_mse <- mean((resid_tr - rf_oob)^2)
oob_r2  <- 1 - oob_mse / var(resid_tr)
if (!is.finite(oob_r2) || oob_r2 <= 0) w_hat <- 0
rf_resid_te <- predict(rf_model, newdata = X_te_raw)
yhat_hybrid[i] <- as.numeric(pl$pred_te + w_hat * rf_resid_te)
}
# metrics
oos <- df %>%
mutate(yhat_ar1      = yhat_ar1,
yhat_rw0      = yhat_rw0,
yhat_rw_drift = yhat_rw_drift,
yhat_hybrid   = yhat_hybrid) %>%
filter(!is.na(yhat_ar1) & !is.na(yhat_hybrid))
rmse <- function(e) sqrt(mean(e^2))
y    <- oos[[target_col]]
e_ar1 <- y - oos$yhat_ar1
e_rw0 <- y - oos$yhat_rw0
e_hy  <- y - oos$yhat_hybrid
da <- function(y, yhat, drop_zero = TRUE){
sy <- sign(y); sf <- sign(yhat)
ok <- is.finite(sy) & is.finite(sf)
if (drop_zero) ok <- ok & sy != 0 & sf != 0
mean(sy[ok] == sf[ok])
}
tibble::tibble(
horizon              = paste0(h, "m"),
window_W             = W,
first_decision_date  = df$date[i_start],
n_oos                = nrow(oos),
RMSE_AR1             = rmse(e_ar1),
RMSE_RW0             = rmse(e_rw0),
RMSE_HYBRID          = rmse(e_hy),
R2_OOS_AR1_vs_RW0    = 1 - sum(e_ar1^2) / sum(e_rw0^2),
R2_OOS_HY_vs_RW0     = 1 - sum(e_hy^2)  / sum(e_rw0^2),
DA_AR1               = da(y, oos$yhat_ar1, TRUE),
DA_RW0               = da(y, oos$yhat_rw0, TRUE),
DA_HYBRID            = da(y, oos$yhat_hybrid, TRUE)
)
}
df_3m <- read_csv("../data/df_3m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_3m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_3m), !is.na(monthly_return_lag1))
h <- 3                # 3-month horizon
summary_tbl <- run_rolling_hybrid_v2(df_3m,
target_col = "Y_log_return_3m",
lag1_col   = "monthly_return_lag1",
h = h,
cutoff = as.Date("2012-12-01"))
print(summary_tbl)
setwd("~/Desktop/y4s1/ec4308/4308_project/src")
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(dplyr)
library(nnet)
})
set.seed(42)
# ---- helpers ----
standardize_train_test <- function(X_tr, X_te) {
mu  <- apply(X_tr, 2, mean)
sdv <- apply(X_tr, 2, sd)
sdv[!is.finite(sdv) | sdv == 0] <- 1
X_tr_s <- scale(X_tr, center = mu, scale = sdv)
X_te_s <- scale(X_te, center = mu, scale = sdv)
list(X_tr_s = as.matrix(X_tr_s), X_te_s = as.matrix(X_te_s))
}
rmse <- function(e) sqrt(mean(e^2))
da   <- function(y, yhat, drop_zero = TRUE) {
sy <- sign(y); sf <- sign(yhat)
ok <- is.finite(sy) & is.finite(sf)
if (drop_zero) ok <- ok & sy != 0 & sf != 0
mean(sy[ok] == sf[ok])
}
# =============================================================================
# Horizon-aware rolling ANN (walk-forward)
# df           : time-ordered data.frame with 'date' (Date), targets, predictors
# h            : horizon in {1,3,6,12}
# target_col   : OPTIONAL; by default uses paste0("Y_log_return_", h, "m")
# lag1_col     : OPTIONAL; used only for AR(1) baseline. If NULL:
#                  - tries paste0("monthly_return_lag", h)
#                  - else falls back to "monthly_return_lag1" if present
# predictors   : OPTIONAL character vector; by default uses ALL columns except date & target
# cutoff       : initial window endpoint (same meaning as your setup)
# ann_hid/decay/maxit : nnet hyperparams
# use_rw_drift : if TRUE, RW baseline uses rolling mean; else zero (RW0)
# returns      : summary tibble + invisibly attaches oos preds if you want to keep them
# =============================================================================
run_rolling_ann_h <- function(df, h = 3,
target_col = NULL,
lag1_col = NULL,
predictors = NULL,
cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3, ann_maxit = 500,
use_rw_drift = FALSE) {
stopifnot(inherits(df$date, "Date"))
df <- df[order(df$date), ]
# --- infer columns based on horizon ---
if (is.null(target_col)) {
target_col <- paste0("Y_log_return_", h, "m")
}
if (!(target_col %in% names(df))) {
stop("Target column '", target_col, "' not found in df.")
}
if (is.null(lag1_col)) {
cand <- paste0("monthly_return_lag", h)
lag1_col <- if (cand %in% names(df)) cand else if ("monthly_return_lag1" %in% names(df)) "monthly_return_lag1" else NA_character_
}
if (!is.na(lag1_col) && !(lag1_col %in% names(df))) {
stop("lag1_col '", lag1_col, "' not found in df.")
}
# predictor set
if (is.null(predictors)) {
predictors <- setdiff(names(df), c("date", target_col))
} else {
missing <- setdiff(predictors, names(df))
if (length(missing)) stop("Predictors not in df: ", paste(missing, collapse = ", "))
}
num_X <- predictors[sapply(df[, predictors, drop = FALSE], is.numeric)]
if (!length(num_X)) stop("No numeric predictors available for ANN.")
# --- window size W as in your convention ---
if (!is.na(lag1_col)) {
W <- df %>%
filter(date <= cutoff, !is.na(.data[[target_col]]), !is.na(.data[[lag1_col]])) %>%
nrow()
} else {
W <- df %>% filter(date <= cutoff, !is.na(.data[[target_col]])) %>% nrow()
}
idx_cut <- which(df$date == cutoff)
i_start <- idx_cut + h
n <- nrow(df)
yhat_ar1 <- rep(NA_real_, n)
yhat_rw0 <- rep(0, n)
yhat_ann <- rep(NA_real_, n)
for (i in seq_len(n)) {
tr_end   <- i - h
tr_start <- tr_end - W + 1
if (tr_start < 1) next
# ---- AR(1) baseline (only if lag1_col is known) ----
if (!is.na(lag1_col)) {
fit_ar1 <- try(lm(reformulate(lag1_col, response = target_col),
data = df[tr_start:tr_end, ]), silent = TRUE)
if (!inherits(fit_ar1, "try-error")) {
yhat_ar1[i] <- predict(fit_ar1, newdata = df[i, , drop = FALSE])
}
}
# ---- RW baseline ----
if (isTRUE(use_rw_drift)) {
mu_h <- mean(df[tr_start:tr_end, target_col, drop = TRUE], na.rm = TRUE)
yhat_rw0[i] <- mu_h
} else {
yhat_rw0[i] <- 0
}
# ---- build train/test for ANN ----
df_tr <- df[tr_start:tr_end, c(target_col, num_X), drop = FALSE]
df_te <- df[i, c(target_col, num_X), drop = FALSE]
good_tr <- complete.cases(df_tr)
if (!any(good_tr)) next
df_tr <- df_tr[good_tr, , drop = FALSE]
if (!all(complete.cases(df_te))) next
y_tr <- df_tr[[target_col]]
X_tr <- as.matrix(df_tr[, num_X, drop = FALSE])
X_te <- as.matrix(df_te[, num_X, drop = FALSE])
std    <- standardize_train_test(X_tr, X_te)
X_tr_s <- std$X_tr_s; X_te_s <- std$X_te_s
ann_fit <- nnet(x = X_tr_s, y = y_tr,
size = ann_hid, decay = ann_decay,
linout = TRUE, maxit = ann_maxit, trace = FALSE)
yhat_ann[i] <- as.numeric(predict(ann_fit, X_te_s))
}
# ---- OOS evaluation ----
oos <- df %>%
mutate(yhat_ar1 = yhat_ar1,
yhat_rw0 = yhat_rw0,
yhat_ann = yhat_ann) %>%
filter(!is.na(yhat_ann))
y     <- oos[[target_col]]
e_rw0 <- y - oos$yhat_rw0
e_ann <- y - oos$yhat_ann
e_ar1 <- if (!all(is.na(oos$yhat_ar1))) y - oos$yhat_ar1 else NA_real_
out <- tibble::tibble(
horizon              = paste0(h, "m"),
window_W             = W,
first_decision_date  = df$date[i_start],
n_oos                = nrow(oos),
RMSE_RW0             = rmse(e_rw0),
RMSE_ANN             = rmse(e_ann),
R2_OOS_ANN_vs_RW0    = 1 - sum(e_ann^2) / sum(e_rw0^2),
DA_RW0               = da(y, oos$yhat_rw0, TRUE),
DA_ANN               = da(y, oos$yhat_ann, TRUE)
)
if (!all(is.na(oos$yhat_ar1))) {
out$RMSE_AR1 <- rmse(e_ar1)
out$DA_AR1   <- da(y, oos$yhat_ar1, TRUE)
}
attr(out, "oos") <- oos  # keep predictions if you want to ensemble later
out
}
# h = 1, 3, 6, 12 (expects columns Y_log_return_1m/3m/6m/12m)
df_1m <- read_csv("../data/df_1m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_1m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_1m), !is.na(monthly_return_lag1))
df_3m <- read_csv("../data/df_3m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_3m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_3m), !is.na(monthly_return_lag1))
df_6m <- read_csv("../data/df_6m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_6m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_6m), !is.na(monthly_return_lag1))
df_12m <- read_csv("../data/df_12m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_12m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_12m), !is.na(monthly_return_lag1))
res1 <- run_rolling_ann_h(df_1m, h = 1, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res3 <- run_rolling_ann_h(df_3m, h = 3, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res6 <- run_rolling_ann_h(df_6m, h = 6, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res12 <- run_rolling_ann_h(df_12m, h = 12, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
dplyr::bind_rows(res1, res3, res6, res12)
# h = 1, 3, 6, 12 (expects columns Y_log_return_1m/3m/6m/12m)
df_1m <- read_csv("../data/df_1m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_1m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_1m), !is.na(monthly_return_lag1))
df_3m <- read_csv("../data/df_3m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_3m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_3m), !is.na(monthly_return_lag1))
df_6m <- read_csv("../data/df_6m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_6m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_6m), !is.na(monthly_return_lag1))
df_12m <- read_csv("../data/df_12m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_12m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_12m), !is.na(monthly_return_lag1))
res1 <- run_rolling_ann_h(df_1m, h = 1, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res3 <- run_rolling_ann_h(df_3m, h = 3, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res6 <- run_rolling_ann_h(df_6m, h = 6, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
res12 <- run_rolling_ann_h(df_12m, h = 12, cutoff = as.Date("2012-12-01"),
ann_hid = 4, ann_decay = 1e-3)
dplyr::bind_rows(res1, res3, res6, res12)
set.seed(42)
grid <- expand.grid(
size  = c(2, 3, 4, 6, 8),
decay = 10^seq(-5, -1, by = 1),  # 1e-5 ... 1e-1
maxit = c(300, 500, 800)
)
eval_grid <- function(df, h, cutoff) {
res <- lapply(seq_len(nrow(grid)), function(i){
g <- grid[i, ]
out <- run_rolling_ann_h(
df          = df,
h           = h,
cutoff      = cutoff,
ann_hid     = g$size,
ann_decay   = g$decay,
ann_maxit   = g$maxit,
use_rw_drift = FALSE
)
cbind(grid[i, ], as.data.frame(out))
})
dplyr::bind_rows(res)
}
# Example: tune for 3-month horizon
tune3 <- eval_grid(df_3m, h = 3, cutoff = as.Date("2012-12-01"))
# Rank by RMSE (primary) then DA (secondary)
best3 <- tune3 %>%
dplyr::arrange(RMSE_ANN, dplyr::desc(DA_ANN)) %>%
dplyr::slice(1)
best3
tune1 <- eval_grid(df_1m, h = 1, cutoff = as.Date("2012-12-01"))
# Rank by RMSE (primary) then DA (secondary)
best1 <- tune1 %>%
dplyr::arrange(RMSE_ANN, dplyr::desc(DA_ANN)) %>%
dplyr::slice(1)
best1
res_best1 <- run_rolling_ann_h(
df          = df_1m,
h           = 1,
cutoff      = as.Date("2012-12-01"),
ann_hid     = best1$size,
ann_decay   = best1$decay,
ann_maxit   = best1$maxit
)
oos_best1 <- attr(res_best, "oos")
oos_best1 <- attr(res_best1, "oos")
target1   <- "Y_log_return_1m"
errors_best1 <- oos_best1[[target1]] - oos_best1$yhat_ann1
err_tbl1 <- oos_best1 %>%
transmute(date,
y    = !!sym(target1),
yhat = yhat_ann1,
error = y - yhat1)
res_best1 <- run_rolling_ann_h(
df          = df_1m,
h           = 1,
cutoff      = as.Date("2012-12-01"),
ann_hid     = best1$size,
ann_decay   = best1$decay,
ann_maxit   = best1$maxit
)
oos_best1 <- attr(res_best1, "oos")
target   <- "Y_log_return_1m"
errors_best1 <- oos_best1[[target]] - oos_best1$yhat_ann
err_tbl1 <- oos_best1 %>%
transmute(date,
y    = !!sym(target),
yhat = yhat_ann,
error = y - yhat)
err_tbl1
res_best3 <- run_rolling_ann_h(
df          = df_3m,
h           = 3,
cutoff      = as.Date("2012-12-01"),
ann_hid     = best3$size,
ann_decay   = best3$decay,
ann_maxit   = best3$maxit
)
oos_best3 <- attr(res_best3, "oos")
target   <- "Y_log_return_3m"
errors_best3 <- oos_best3[[target]] - oos_best3$yhat_ann
err_tbl3 <- oos_best3 %>%
transmute(date,
y    = !!sym(target),
yhat = yhat_ann,
error = y - yhat)
err_tbl3
write.csv(err_tbl1, "../data/ann_err_tbl1.csv", row.names = FALSE)
write.csv(err_tbl3, "../data/ann_err_tbl3.csv", row.names = FALSE)
tune6 <- eval_grid(df_6m, h = 6, cutoff = as.Date("2012-12-01"))
# Rank by RMSE (primary) then DA (secondary)
best6 <- tune6 %>%
dplyr::arrange(RMSE_ANN, dplyr::desc(DA_ANN)) %>%
dplyr::slice(1)
best6
res_best6 <- run_rolling_ann_h(
df          = df_6m,
h           = 6,
cutoff      = as.Date("2012-12-01"),
ann_hid     = best6$size,
ann_decay   = best6$decay,
ann_maxit   = best6$maxit
)
oos_best6 <- attr(res_best6, "oos")
target   <- "Y_log_return_6m"
errors_best6 <- oos_best6[[target]] - oos_best6$yhat_ann
err_tbl6 <- oos_best6 %>%
transmute(date,
y    = !!sym(target),
yhat = yhat_ann,
error = y - yhat)
#err_tbl3
write.csv(err_tbl6, "../data/ann_err_tbl6.csv", row.names = FALSE)
# Example: tune for 3-month horizon
tune12 <- eval_grid(df_12m, h = 12, cutoff = as.Date("2012-12-01"))
# Rank by RMSE (primary) then DA (secondary)
best12 <- tune12 %>%
dplyr::arrange(RMSE_ANN, dplyr::desc(DA_ANN)) %>%
dplyr::slice(1)
best12
res_best12 <- run_rolling_ann_h(
df          = df_12m,
h           = 12,
cutoff      = as.Date("2012-12-01"),
ann_hid     = best12$size,
ann_decay   = best12$decay,
ann_maxit   = best12$maxit
)
oos_best12 <- attr(res_best12, "oos")
target   <- "Y_log_return_12m"
errors_best12 <- oos_best12[[target]] - oos_best12$yhat_ann
err_tbl12 <- oos_best12 %>%
transmute(date,
y    = !!sym(target),
yhat = yhat_ann,
error = y - yhat)
#err_tbl3
write.csv(err_tbl12, "../data/ann_err_tbl12.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
# ---- read dataset ----
df_1m <- read_csv("../data/df_1m_lag.csv", show_col_types = FALSE) %>%
select(date, Y_log_return_1m, monthly_return_lag1) %>%
arrange(date) %>%
filter(!is.na(Y_log_return_1m), !is.na(monthly_return_lag1))
h <- 1
# ---- rolling window size ----
cutoff <- as.Date ('2012-12-01')
W <- df_1m %>%
filter (date <= cutoff, !is.na(Y_log_return_1m),!is.na(monthly_return_lag1)) %>%
nrow()
idx_cut <- which(df_1m$date == cutoff)
i_start <- idx_cut + h
# ---- fit AR ----
n <- nrow(df_1m)
yhat_ar1 <- rep(NA_real_, n)
yhat_rw0 <- rep(0, n)
yhat_rw_drift <- rep(NA_real_, n)
for (i in seq_len(n)) {
tr_end   <- i - h
tr_start <- tr_end - W + 1
if (tr_start < 1) next
fit <- lm(Y_log_return_1m ~ monthly_return_lag1,
data = df_1m[tr_start:tr_end, ])
yhat_ar1[i] <- predict(fit, newdata = df_1m[i, , drop = FALSE])
mu_h <- mean(df_1m[tr_start:tr_end, "Y_log_return_1m", drop=TRUE], na.rm = TRUE)
yhat_rw_drift[i] <- mu_h
}
# ---- calculate rmse ----
oos <- df_1m %>%
mutate(yhat_ar1 = yhat_ar1,
yhat_rw0 = yhat_rw0,
yhat_rw_drift = yhat_rw_drift) %>%
filter(!is.na(yhat_ar1))
rmse <- function(e) sqrt(mean(e^2))
e_ar1 <- oos$Y_log_return_1m - oos$yhat_ar1
e_rw0 <- oos$Y_log_return_1m - oos$yhat_rw0
e_rw_dr <- oos$Y_log_return_1m - oos$yhat_rw_drift
# ---- directional accuracy (exclude zeros by default) ----
da <- function(y, yhat, drop_zero = TRUE) {
sy <- sign(y); sf <- sign(yhat)
ok <- is.finite(sy) & is.finite(sf)
if (drop_zero) ok <- ok & sy != 0 & sf != 0
mean(sy[ok] == sf[ok])
}
DA_AR1      <- da(oos$Y_log_return_1m, oos$yhat_ar1, drop_zero = TRUE)
DA_RW0      <- da(oos$Y_log_return_1m, oos$yhat_rw0, drop_zero = TRUE)
DA_RW_DRIFT <- da(oos$Y_log_return_1m, oos$yhat_rw_drift, drop_zero = TRUE)
# ---- output summary ----
summary_tbl <- tibble::tibble(
horizon            = paste0(h, "m"),
window_W           = W,
first_decision_date= df_1m$date[i_start],
n_oos              = nrow(oos),
RMSE_AR1           = rmse(e_ar1),
RMSE_RW0           = rmse(e_rw0),
RMSE_RW_DRIFT      = rmse(e_rw_dr),
R2_OOS             = 1 - sum(e_ar1^2) / sum(e_rw0^2),
DA_AR1             = DA_AR1,
DA_RW0             = DA_RW0,
DA_RW_DRIFT        = DA_RW_DRIFT
)
print(summary_tbl)
oos
oostbl = oos %>% select (date, Y_log_return_1m, yhat_ar1) %>%
mutate (error = Y_log_return_1m - yhat_ar1)
oostbl
write.csv(oostbl, "../data/ar1_err_tbl1.csv", row.names = FALSE)
best12
best6
best1
best3
